{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cse-teacher/suggestion-mining/blob/main/suggestion_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMyi6aqLVl_v"
      },
      "source": [
        "# Suggestion Mining\n",
        "Suggestion mining is the task of extracting suggestions from user reviews\n",
        "\n",
        "Developed: 11 Feb 2024 \\\\\n",
        "Last Update: 11 Feb 2024 \\\\\n",
        "Author: Muharram Mansoorizadeh plus Various AI tools (Google search, chatGPT, Gemini , ...)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0rqNS_w7Wvo"
      },
      "source": [
        "## Install Required Packagaes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMhPx71AqsaM",
        "outputId": "3c30e507-91d9-48b6-c382-c0ca0a1fefb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in c:\\python\\python38\\lib\\site-packages (2.10.1)\n",
            "Requirement already satisfied: cleantext in c:\\python\\python38\\lib\\site-packages (1.1.4)\n",
            "Requirement already satisfied: nltk in c:\\python\\python38\\lib\\site-packages (from cleantext) (3.8.1)\n",
            "Requirement already satisfied: click in c:\\python\\python38\\lib\\site-packages (from nltk->cleantext) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\python\\python38\\lib\\site-packages (from nltk->cleantext) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\python\\python38\\lib\\site-packages (from nltk->cleantext) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in c:\\python\\python38\\lib\\site-packages (from nltk->cleantext) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\python\\python38\\lib\\site-packages (from click->nltk->cleantext) (0.4.6)\n",
            "Requirement already satisfied: nltk in c:\\python\\python38\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\python\\python38\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\python\\python38\\lib\\site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\python\\python38\\lib\\site-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in c:\\python\\python38\\lib\\site-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: pyenchant in c:\\python\\python38\\lib\\site-packages (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\python\\python38\\lib\\site-packages (1.3.2)\n",
            "Requirement already satisfied: lightgbm in c:\\python\\python38\\lib\\site-packages (4.3.0)\n",
            "Requirement already satisfied: catboost in c:\\python\\python38\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\python\\python38\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python\\python38\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: graphviz in c:\\python\\python38\\lib\\site-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in c:\\python\\python38\\lib\\site-packages (from catboost) (3.7.5)\n",
            "Requirement already satisfied: pandas>=0.24 in c:\\python\\python38\\lib\\site-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: plotly in c:\\python\\python38\\lib\\site-packages (from catboost) (5.19.0)\n",
            "Requirement already satisfied: six in c:\\python\\python38\\lib\\site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python\\python38\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python\\python38\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\python\\python38\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (6.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\python\\python38\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\python\\python38\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.17.0)\n",
            "Requirement already satisfied: gensim in c:\\python\\python38\\lib\\site-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\python\\python38\\lib\\site-packages (from gensim) (1.24.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\python\\python38\\lib\\site-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\python\\python38\\lib\\site-packages (from gensim) (7.0.1)\n",
            "Requirement already satisfied: wrapt in c:\\python\\python38\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: transformers in c:\\python\\python38\\lib\\site-packages (4.38.2)\n",
            "Requirement already satisfied: sentencepiece in c:\\python\\python38\\lib\\site-packages (0.2.0)\n",
            "Requirement already satisfied: sacremoses in c:\\python\\python38\\lib\\site-packages (0.1.1)\n",
            "Requirement already satisfied: filelock in c:\\python\\python38\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\python\\python38\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python\\python38\\lib\\site-packages (from transformers) (1.24.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python\\python38\\lib\\site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python\\python38\\lib\\site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python\\python38\\lib\\site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in c:\\python\\python38\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\python\\python38\\lib\\site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\python\\python38\\lib\\site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\python\\python38\\lib\\site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: click in c:\\python\\python38\\lib\\site-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\python\\python38\\lib\\site-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: colorama in c:\\python\\python38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\python38\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python38\\lib\\site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\python38\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python38\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: ekphrasis in c:\\python\\python38\\lib\\site-packages (0.5.4)\n",
            "Requirement already satisfied: termcolor in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (2.4.0)\n",
            "Requirement already satisfied: tqdm in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (0.4.6)\n",
            "Requirement already satisfied: ujson in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (5.9.0)\n",
            "Requirement already satisfied: matplotlib in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (3.7.5)\n",
            "Requirement already satisfied: nltk in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (3.8.1)\n",
            "Requirement already satisfied: ftfy in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (6.1.3)\n",
            "Requirement already satisfied: numpy in c:\\python\\python38\\lib\\site-packages (from ekphrasis) (1.24.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\python\\python38\\lib\\site-packages (from ftfy->ekphrasis) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib->ekphrasis) (6.1.3)\n",
            "Requirement already satisfied: click in c:\\python\\python38\\lib\\site-packages (from nltk->ekphrasis) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\python\\python38\\lib\\site-packages (from nltk->ekphrasis) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\python\\python38\\lib\\site-packages (from nltk->ekphrasis) (2023.12.25)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\python\\python38\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->ekphrasis) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#Install required packages and libraries\n",
        "\n",
        "!apt-get install libenchant-2-2\n",
        "!pip install emoji\n",
        "!pip install cleantext\n",
        "!pip install nltk\n",
        "!pip install pyenchant\n",
        "!pip install scikit-learn lightgbm catboost\n",
        "!pip install gensim\n",
        "!pip install transformers sentencepiece sacremoses\n",
        "!pip install ekphrasis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUeHgN3BM3x0"
      },
      "source": [
        "## Import data\n",
        "\n",
        "Get the required data files from github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PGYc5OXNBFh",
        "outputId": "1b7832c2-fb07-4719-892c-3bfa8f68bb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'suggestion-mining'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cse-teacher/suggestion-mining.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2FjFI8E7gDn"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xWr3Gqpm9264"
      },
      "outputs": [],
      "source": [
        "# Read data from input files\n",
        "#Reset environment\n",
        "%reset -f\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "#reset stdout\n",
        "sys.stdout  = sys.__stdout__\n",
        "\n",
        "#Set default seed:\n",
        "random.seed(42)\n",
        "\n",
        "#Main Application\n",
        "folder     = \"./suggestion-mining/data/\"\n",
        "train_file = folder + \"V1.4_Training.csv\" #\"Train_Augmented_03.csv\" # V1.4_Training.csv\" #  \"Train_processed.csv\" /suggestion-mining/data/Train_Augmented_03.csv\n",
        "valid_file = folder + \"SubtaskA_Trial_Test_Labeled.csv\" #\"validation_processed.csv\"\n",
        "test_file  = folder + \"SubtaskA_EvaluationData_labeled.csv\"\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(train_file,\n",
        "                       encoding_errors='ignore', header=None,\n",
        "                       names=[\"id\", \"sentence\", \"label\"])\n",
        "\n",
        "valid_df = pd.read_csv(valid_file,\n",
        "                       encoding_errors='ignore', header=None,\n",
        "                       names=[\"id\", \"sentence\", \"label\"])\n",
        "\n",
        "test_df  = pd.read_csv(test_file,\n",
        "                       encoding_errors='ignore', header=None,\n",
        "                       names=[\"id\", \"sentence\", \"label\"])\n",
        "\n",
        "all_df = pd.concat([train_df, valid_df, test_df], axis=0)\n",
        "\n",
        "\n",
        "#Get the labels:\n",
        "y_train_original = train_df['label'].values\n",
        "y_valid_original = valid_df['label'].values\n",
        "y_test_original  = test_df['label'].values\n",
        "y_all_original  = all_df['label'].values\n",
        "train_size = len(train_df['label'])\n",
        "valid_size = len(valid_df['label'])\n",
        "test_size  = len(test_df['label'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsaeHSk9PmO1"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npr8F9hTQzwG",
        "outputId": "d1e8d0d2-3666-404a-f4eb-8dbc03115ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
            "[nltk_data]     connection attempt failed because the connected party\n",
            "[nltk_data]     did not properly respond after a period of time, or\n",
            "[nltk_data]     established connection failed because connected host\n",
            "[nltk_data]     has failed to respond>\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import re\n",
        "import nltk\n",
        "import cleantext\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_nonalphanumeric(text):\n",
        "    #text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
        "  text = re.sub(r'\\W+', ' ', text)\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "  return text\n",
        "\n",
        "def remove_stopwords_list(tokens):\n",
        "  filtered_tokens = [w for w in tokens if not w.lower() in stop_words]\n",
        "  return filtered_tokens\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  filtered_tokens = remove_stopwords_list(tokens)\n",
        "  return ' '.join(filtered_tokens)\n",
        "\n",
        "#-----------------------------------\n",
        "# Replace hyperlinks\n",
        "#\n",
        "def replace_hyperlinks(text):\n",
        "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "  return text\n",
        "\n",
        "def stem(text):\n",
        "  tokens = word_tokenize(text.strip())\n",
        "  tokens_stem =[stemmer.stem(s) for s in tokens]\n",
        "  return ' '.join(tokens_stem)\n",
        "\n",
        "#----------------------------------------\n",
        "# replace_named_entities:\n",
        "#    Replaces each word or phrase in the input text with its\n",
        "#    Named Entity Recognition (NER) tag label.\n",
        "#    Args:\n",
        "#    text (str): Input text\n",
        "#\n",
        "#    Returns:\n",
        "#    str: Text with named entities replaced by their NER tag labels\n",
        "#\n",
        "def replace_named_entities(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Tag the words with Part-of-Speech (POS) tags\n",
        "    tagged_words = pos_tag(words)\n",
        "\n",
        "    # Perform Named Entity Recognition (NER)\n",
        "    named_entities = ne_chunk(tagged_words)\n",
        "\n",
        "    # Replace entities with their NER tag labels\n",
        "    replaced_text = []\n",
        "    for entity in named_entities:\n",
        "        if isinstance(entity, nltk.tree.Tree):\n",
        "            label = entity.label()\n",
        "            named_entity_text = \" \".join([word for word, tag in entity.leaves()])\n",
        "            #replaced_text.append(f'<{label}>{named_entity_text}</{label}>')\n",
        "            replaced_text.append(f'{label}')\n",
        "            #replaced_text.append('')\n",
        "        else:\n",
        "            replaced_text.append(entity[0])\n",
        "\n",
        "    return \" \".join(replaced_text)\n",
        "\n",
        "#Global callings:\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Example usage:\n",
        "text = \"Microsoft should seriously look into getting rid of Syamentc for all these paying stuff\"\n",
        "replaced_text = replace_named_entities(text)\n",
        "print(\"Replaced Text:\", replaced_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "op_replace_hyperlinks      = True\n",
        "op_remove_nonalphanumeric  = True\n",
        "op_remove_stopwords        = False\n",
        "op_replace_named_entities  = True\n",
        "op_stem                    = True\n",
        "\n",
        "if op_replace_hyperlinks == True:\n",
        "  #replace named entities with their tag names:\n",
        "  train_df['sentence']  = train_df['sentence'].apply(replace_hyperlinks)\n",
        "  test_df['sentence']   = test_df['sentence'].apply(replace_hyperlinks)\n",
        "  valid_df['sentence']  = valid_df['sentence'].apply(replace_hyperlinks)\n",
        "  all_df['sentence']    = all_df['sentence'].apply(replace_hyperlinks)\n",
        "\n",
        "if op_remove_nonalphanumeric == True:\n",
        "  train_df['sentence'] = train_df['sentence'].apply(remove_nonalphanumeric)\n",
        "  valid_df['sentence'] = valid_df['sentence'].apply(remove_nonalphanumeric)\n",
        "  test_df['sentence']  = test_df['sentence'].apply(remove_nonalphanumeric)\n",
        "  all_df['sentence']   = all_df['sentence'].apply(remove_nonalphanumeric)\n",
        "\n",
        "if op_replace_named_entities == True:\n",
        "  train_df['sentence']  = train_df['sentence'].apply(replace_named_entities)\n",
        "  test_df['sentence']   = test_df['sentence'].apply(replace_named_entities)\n",
        "  valid_df['sentence']  = valid_df['sentence'].apply(replace_named_entities)\n",
        "  all_df['sentence']    = all_df['sentence'].apply(replace_named_entities)\n",
        "\n",
        "if op_remove_stopwords == True:\n",
        "  train_df['sentence'] = train_df['sentence'].apply(remove_stopwords)\n",
        "  valid_df['sentence'] = valid_df['sentence'].apply(remove_stopwords)\n",
        "  test_df['sentence']  = test_df['sentence'].apply(remove_stopwords)\n",
        "  all_df['sentence']   = all_df['sentence'].apply(remove_stopwords)\n",
        "\n",
        "if op_stem == True:\n",
        "  train_df['sentence'] = train_df['sentence'].apply(stem)\n",
        "  valid_df['sentence'] = valid_df['sentence'].apply(stem)\n",
        "  test_df['sentence']  = test_df['sentence'].apply(stem)\n",
        "  all_df['sentence']   = all_df['sentence'].apply(stem)\n"
      ],
      "metadata": {
        "id": "ceUQZN9Ltd8s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['sentence'][1:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFHg96jPWWUO",
        "outputId": "9652a827-d88e-4251-c8dd-f65c97977a52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    gpe in your csproj file there is a organ entri...\n",
              "2    gpe mean the new version not fulli replac the ...\n",
              "3    some of my user will still receiv the old xap ...\n",
              "4    the store random give the old xap or the new x...\n",
              "5    my app has a organ version and a organ version...\n",
              "6    the wp7 xap work onli on organ and the wp8 xap...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqJSjOY3bZPl"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oMghoc88kqxr"
      },
      "outputs": [],
      "source": [
        "#Extract BOW feature test\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "#----------------------\n",
        "# BOW Features\n",
        "bow_vectorizer = CountVectorizer(analyzer='word',\n",
        "                                 stop_words=None,\n",
        "                                 lowercase=True,\n",
        "                                 encoding='utf-8',\n",
        "                                 min_df = 5 , #                                 max_features = 5000,\n",
        "                                 max_df = 0.975,\n",
        "                                 ngram_range =(1,5))\n",
        "\n",
        "bow_vectorizer.fit(all_df['sentence'])\n",
        "train_bow_features = bow_vectorizer.transform(train_df['sentence']).toarray()\n",
        "valid_bow_features = bow_vectorizer.transform(valid_df['sentence']).toarray()\n",
        "test_bow_features  = bow_vectorizer.transform(test_df['sentence']).toarray()\n",
        "all_bow_features   = bow_vectorizer.transform(all_df['sentence']).toarray()\n",
        "\n",
        "#----------------------\n",
        "# TF-IDF Features\n",
        "\n",
        "# Fit the vectorizer on the sentences to learn vocabulary and IDF weights\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=None,\n",
        "                                 lowercase=True,\n",
        "                                 encoding='utf-8',\n",
        "                                 min_df = 5 ,\n",
        "                                 max_df = 0.95, #                                 max_features = 5000,\n",
        "                                 ngram_range =(1,5))\n",
        "\n",
        "tfidf_vectorizer.fit(all_df['sentence'])\n",
        "\n",
        "# Transform the sentences into tf-idf vectors\n",
        "train_tfidf_features = tfidf_vectorizer.transform(train_df['sentence']).toarray()\n",
        "test_tfidf_features  = tfidf_vectorizer.transform(test_df['sentence']).toarray()\n",
        "valid_tfidf_features = tfidf_vectorizer.transform(valid_df['sentence']).toarray()\n",
        "all_tfidf_features   = tfidf_vectorizer.transform(all_df['sentence']).toarray()\n",
        "\n",
        "'''\n",
        "#------------------------------------------------\n",
        "# word2vec features\n",
        "#\n",
        "docs = [wordpunct_tokenize(doc) for doc in all_df['sentence']]\n",
        "docs1 = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs)]\n",
        "model = Doc2Vec(docs1, vector_size=50, window=2, min_count=1, workers=4)\n",
        "\n",
        "#Get the features:\n",
        "vectors = [model.infer_vector(doc) for doc in(docs)]\n",
        "all_d2v_features = np.array(vectors)\n",
        "train_d2v_features = all_d2v_features[0:train_size,:]\n",
        "valid_d2v_features = all_d2v_features[train_size:train_size+valid_size,:]\n",
        "test_d2v_features  = all_d2v_features[train_size+valid_size:,:]\n",
        "'''\n",
        "\n",
        "#define global features, empty at first:\n",
        "X_train     = np.empty([])\n",
        "X_test      = np.empty([])\n",
        "X_valid     = np.empty([])\n",
        "X_all       = np.empty([])\n",
        "X_train_val = np.empty([])\n",
        "\n",
        "y_train = y_train_original\n",
        "y_valid = y_valid_original\n",
        "y_test  = y_test_original\n",
        "y_all   = y_all_original\n",
        "y_train_val = np.concatenate((y_train , y_valid), axis= 0 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srQ0TELENoKf"
      },
      "source": [
        "# Experiments\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzpAtHXe5qsC"
      },
      "source": [
        "## Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h7Yunwtnxl3c"
      },
      "outputs": [],
      "source": [
        "#===============================================\n",
        "# Utility functions\n",
        "#\n",
        "\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import csv\n",
        "from tensorflow import keras\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization ,Dropout\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "#------------------------------------------------\n",
        "# apply the given option\n",
        "#\n",
        "def select_optional_features(feature_group,\n",
        "                 op_scale_features  = False,\n",
        "                 op_filter_df       = False,\n",
        "                 op_upsample_smote  = False,\n",
        "                 op_upsample_over   = False,\n",
        "                 op_transform_pca   = False,\n",
        "                 op_downsample_majority = False\n",
        "                 ):\n",
        "  global X_train, X_valid, X_test, X_all\n",
        "  global y_train, y_valid, y_test, y_all\n",
        "  global X_train_val , y_train_val\n",
        "\n",
        "  description = feature_group\n",
        "  y_train = y_train_original\n",
        "  y_valid = y_valid_original\n",
        "  y_test  = y_test_original\n",
        "\n",
        "  if feature_group == 'tfidf' :\n",
        "    X_train = train_tfidf_features\n",
        "    X_test  = test_tfidf_features\n",
        "    X_valid = valid_tfidf_features\n",
        "    X_all   = all_tfidf_features\n",
        "  elif feature_group == 'bow':\n",
        "    X_train = train_bow_features\n",
        "    X_test  = test_bow_features\n",
        "    X_valid = valid_bow_features\n",
        "    X_all   = all_bow_features\n",
        "  elif feature_group == 'd2v':\n",
        "    X_train = train_d2v_features\n",
        "    X_test  = test_d2v_features\n",
        "    X_valid = valid_d2v_features\n",
        "    X_all   = all_d2v_features\n",
        "\n",
        "  if op_scale_features == True: # Scale numerical features\n",
        "     scaler  = StandardScaler().fit(X_all); description += ', Standard Scaler'\n",
        "     X_all   = scaler.transform(X_all)\n",
        "     X_train = scaler.transform(X_train)\n",
        "     X_test  = scaler.transform(X_test)\n",
        "     X_valid = scaler.transform(X_valid)\n",
        "\n",
        "  if op_filter_df == True: # Exclude features with low document frequency\n",
        "     X_all, mask   = filter_bow_mindf(X, min_df=5); description += ', Filter df'\n",
        "     X_all   = scaler.transform(X_all)\n",
        "     X_train = scaler.transform(X_train)\n",
        "     X_test  = scaler.transform(X_test)\n",
        "     X_valid = scaler.transform(X_valid)\n",
        "\n",
        "  if op_upsample_smote == True: # SMOTE oversampling\n",
        "    smote = SMOTE(sampling_strategy=\"minority\") ; description += ', SMOTE Augmentation'\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "  if op_upsample_over == True: # Random oversampling\n",
        "    oversampler = RandomOverSampler(random_state=42); description += ', oversampling Augmentation'\n",
        "    X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "  if op_transform_pca == True:  # Do PCA\n",
        "    pca = PCA(n_components=500).fit(X_all);  description += ', PCA'\n",
        "    X_train = pca.transform(X_train) ; X_test = pca.transform(X_test)\n",
        "    X_valid = pca.transform(X_valid) ; X_all = pca.transform(X_all)\n",
        "\n",
        "  if op_downsample_majority == True:  # Down sample majority class\n",
        "      # Separate instances for class 1\n",
        "    class_1_instances = X_train[y_train == 1,:]\n",
        "    class_0_instances = X_train[y_train == 0,:]\n",
        "    number_of_samples = class_1_instances.shape[0]\n",
        "    indices = np.random.choice(class_0_instances.shape[0], number_of_samples, replace=False)\n",
        "    sampled_class_0_instances = class_0_instances[indices,:]\n",
        "\n",
        "    # Combine instances for class 1 and sampled instances from class 0\n",
        "    X_train = np.concatenate([class_1_instances, sampled_class_0_instances])\n",
        "    y_train = np.concatenate([np.ones(class_1_instances.shape[0]), np.zeros(sampled_class_0_instances.shape[0])])\n",
        "\n",
        "\n",
        "    # Train + Validation data\n",
        "  X_train_val = np.concatenate((X_train, X_valid) , axis=0)\n",
        "  y_train_val = np.concatenate((y_train, y_valid) , axis=0)\n",
        "  return description\n",
        "\n",
        "#----------------------------------\n",
        "# Print results per class\n",
        "#\n",
        "def print_per_class_results(y_actual, y_pred, description=''):\n",
        "  for label in (0,1):\n",
        "    v0 = accuracy_score(y_actual, y_pred)\n",
        "    v1 = precision_score(y_actual, y_pred, pos_label=label)\n",
        "    v2 = recall_score(y_actual, y_pred, pos_label=label)\n",
        "    v3 = f1_score(y_actual, y_pred, pos_label=label)\n",
        "    print(f\"{description},\\t class={label}\\tAccuracy={v0:.2f},\\t Precision={v1:.2f},\\tRecall={v2:.2f}\\tF1-score={v3:.2f}\")\n",
        "\n",
        "\n",
        "#----------------------------------\n",
        "# Print results per class\n",
        "#\n",
        "def print_results(y_actual, y_pred, description=''):\n",
        "  v00 = accuracy_score(y_actual, y_pred)\n",
        "  v01 = precision_score(y_actual, y_pred, pos_label=0)\n",
        "  v02 = recall_score(y_actual, y_pred, pos_label=0)\n",
        "  v03 = f1_score(y_actual, y_pred, pos_label=0)\n",
        "\n",
        "  v11 = precision_score(y_actual, y_pred, pos_label=1)\n",
        "  v12 = recall_score(y_actual, y_pred, pos_label=1)\n",
        "  v13 = f1_score(y_actual, y_pred, pos_label=1)\n",
        "\n",
        "  smsg = f\"{description},\\tAccuracy={v00:.2f},\\tC0: Pr={v01:.2f}, Re={v02:.2f}, F1={v03:.2f},\\tC1: Pr={v11:.2f}, Re={v12:.2f}, F1={v13:.2f}\"\n",
        "  print(smsg)\n",
        "  with open(\"results.txt\", \"a\") as myfile:\n",
        "    myfile.write(f\"{datetime.now()}\\t {smsg}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8KPz9KChLrA"
      },
      "source": [
        "**Experimental Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W7M08KHYgBc5"
      },
      "outputs": [],
      "source": [
        " #select options here and run classifiers as you like:\n",
        "\n",
        " current_options = select_optional_features(feature_group = 'tfidf',\n",
        "                 op_scale_features  = False,\n",
        "                 op_filter_df       = False,\n",
        "                 op_upsample_smote  = False,\n",
        "                 op_upsample_over   = False,\n",
        "                 op_transform_pca   = False ,\n",
        "                 op_downsample_majority = False,\n",
        "\n",
        "                                            )\n",
        "\n",
        " print(current_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Discrimination Analysis**"
      ],
      "metadata": {
        "id": "AQroVkX_1_eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = lda.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "print_results(y_test , y_pred, 'LDA, ' + current_options )\n"
      ],
      "metadata": {
        "id": "m7DrD9Zx0_fD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypMLOuIfkaoB"
      },
      "source": [
        "**Basic Methods**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uLzrQpgakgHf"
      },
      "outputs": [],
      "source": [
        "#Some Useful classifiers\n",
        "classifiers = {\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=21, metric=\"cosine\"),\n",
        "    'Logistic Regression': sklearn.linear_model.LogisticRegression(random_state=42),\n",
        "    'Support Vector Machine-L': sklearn.svm.SVC(kernel='linear', random_state=42),\n",
        "    'Support Vector Machine-R': sklearn.svm.SVC(kernel='rbf', random_state=42),\n",
        "    'Support Vector Machine-S': sklearn.svm.SVC(kernel='sigmoid', random_state=42),\n",
        "    'Support Vector Machine-WL': sklearn.svm.SVC(kernel=\"linear\", class_weight={1: 10}, random_state=42),\n",
        "    'Support Vector Machine-WR': sklearn.svm.SVC(kernel=\"rbf\", class_weight={1: 10}, random_state=42),\n",
        "    'Support Vector Machine-WS': sklearn.svm.SVC(kernel=\"sigmoid\", class_weight={1: 10}, random_state=42),\n",
        "    'Decision Tree classifier': DecisionTreeClassifier(max_depth=15, random_state=42),\n",
        "}\n",
        "\n",
        "# Loop through each classifier and evaluate performance\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train_val, y_train_val)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print_results(y_test , y_pred, name + ', '+ current_options)\n",
        "\n",
        "\n",
        "#---------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdGv3RxdMA5r"
      },
      "source": [
        "**Ensemble Models**\n",
        "\n",
        "This experiment trains well-known ensemble methods on the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z0xQuTCmMCAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548efc69-9527-449a-b862-c8474d6b4aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:   15.6s\n",
            "[Parallel(n_jobs=-1)]: Done 410 tasks      | elapsed:   38.8s\n",
            "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1210 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1760 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2410 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done 3160 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=-1)]: Done 4010 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4960 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  7.8min finished\n",
            "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
            "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=20)]: Done 760 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=20)]: Done 1210 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=20)]: Done 1760 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=20)]: Done 2410 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=20)]: Done 3160 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=20)]: Done 4010 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=20)]: Done 4960 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=20)]: Done 5000 out of 5000 | elapsed:    0.7s finished\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\"     : RandomForestClassifier(n_estimators=5000,class_weight={0:1,1:10}, n_jobs=-1,verbose=1),\n",
        "    \"AdaBoost\"          : AdaBoostClassifier(),\n",
        "    \"Gradient Boosting\" : GradientBoostingClassifier(),\n",
        "    \"Extra Trees\"       : ExtraTreesClassifier(),\n",
        "    \"LightGBM\"          : LGBMClassifier(),\n",
        "    \"CatBoost\"          : CatBoostClassifier(verbose=0)\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "X_train_val = np.concatenate((X_train, X_valid) , axis=0)\n",
        "y_train_val = np.concatenate((y_train, y_valid) , axis=0)\n",
        "\n",
        "# Loop through each classifier and evaluate performance\n",
        "for name, clf in classifiers.items():\n",
        "    description = name + ', '+ current_options\n",
        "    clf.fit(X_train_val, y_train_val)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print_results(y_test , y_pred, description)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHxOrXSPovV0"
      },
      "source": [
        "**Neural Networks**\n",
        "\n",
        "This network is trained on the training and validation sets and\n",
        "tested on the testing set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Input layer\n",
        "        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
        "        self.layers.append(nn.BatchNorm1d(hidden_sizes[0]))\n",
        "        self.layers.append(nn.Sigmoid())\n",
        "        self.layers.append(nn.Dropout(0.2))\n",
        "\n",
        "        # Hidden layers\n",
        "        for i in range(1, len(hidden_sizes)):\n",
        "            self.layers.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
        "            self.layers.append(nn.BatchNorm1d(hidden_sizes[i]))\n",
        "            self.layers.append(nn.ReLU())\n",
        "            self.layers.append(nn.Dropout(0.2))\n",
        "\n",
        "        # Output layer\n",
        "        self.layers.append(nn.Linear(hidden_sizes[-1], 1))\n",
        "        self.layers.append(nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train_val.shape[1]  # Adjust this based on your input features\n",
        "hidden_sizes = [500, 250, 100, 50]\n",
        "\n",
        "# Instantiate the model\n",
        "model_mlp2 = MLPModel(input_size, hidden_sizes)\n",
        "\n",
        "# Check if GPU is available and move the model and data to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_mlp2.to(device)\n",
        "print(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model_mlp2.parameters(), lr=0.001)\n",
        "\n",
        "#Generate balanced dataset for training:\n",
        "# Separate instances for class 1\n",
        "class_1_instances = X_train_val[y_train_val == 1,:]\n",
        "class_0_instances = X_train_val[y_train_val == 0,:]\n",
        "number_of_samples = class_1_instances.shape[0]\n",
        "\n",
        "index             = np.random.choice(class_0_instances.shape[0], number_of_samples, replace=False)\n",
        "sampled_class_0_instances = class_0_instances[index,:]\n",
        "\n",
        "# Combine instances for class 1 and sampled instances from class 0\n",
        "balanced_X = np.concatenate([class_1_instances, sampled_class_0_instances])\n",
        "balanced_y = np.concatenate([np.ones(class_1_instances.shape[0]), np.zeros(sampled_class_0_instances.shape[0])])\n",
        "\n",
        "\n",
        "# Dummy data (replace this with your actual dataset)\n",
        "# Assuming you have X_train and y_train as your training data and labels\n",
        "dummy_data = torch.Tensor(balanced_X).to(device)\n",
        "dummy_labels = torch.Tensor(balanced_y).view(-1, 1).to(device)\n",
        "\n",
        "# Create DataLoader for the dataset\n",
        "dataset = TensorDataset(dummy_data, dummy_labels)\n",
        "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_mlp2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch %100 == 0 :\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Save the trained model if needed\n",
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_datetime = datetime.now()\n",
        "\n",
        "# Format the current date and time into a string\n",
        "model_file_name = 'mlp_model_' + current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".pth\"\n",
        "\n",
        "torch.save(model_mlp2.state_dict(), model_file_name)\n"
      ],
      "metadata": {
        "id": "mjhGuKclSinl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------\n",
        "# Test the network\n",
        "\n",
        "#Prepare test data:\n",
        "new_data = torch.Tensor(X_test) #.to(device)\n",
        "\n",
        "# Create DataLoader for the new dataset\n",
        "new_dataset = TensorDataset(new_data)\n",
        "new_dataloader = DataLoader(new_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load the trained model\n",
        "model = MLPModel(input_size, hidden_sizes)\n",
        "model.load_state_dict(torch.load(model_file_name))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "# Make predictions on the test data\n",
        "with torch.no_grad():\n",
        "  for inputs in new_dataloader:\n",
        "    outputs = model(inputs[0])#(torch.tensor(X_test))\n",
        "    #predictions = torch.round(outputs)\n",
        "    predictions.append(outputs.cpu().data.numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "predictions = np.concatenate(predictions)\n",
        "predictions[predictions<0.001] = 0\n",
        "y_pred = predictions >= 0.5\n",
        "\n",
        "print_results(y_test , y_pred, 'torch nn' + current_options)"
      ],
      "metadata": {
        "id": "2rgKAAuUE6kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T44vTY5NowqV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "82c0c6fd-a125-4a78-8bd9-dc3066dd9189"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define common parameters\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_size, vocab_size  \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;66;03m# Adjust based on your data\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "    #'MLP Network': MLPClassifier(hidden_layer_sizes=(150, 100,50), activation='relu', solver='adam', max_iter=1000),\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Embedding, LSTM, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Define common parameters\n",
        "train_size, vocab_size  = X_train.shape\n",
        "print(X_train.shape)\n",
        "  # Adjust based on your data\n",
        "max_len  = vocab_size  # Adjust based on your data\n",
        "numepochs  = 100\n",
        "\n",
        "model_mlp1 = MLPClassifier(random_state=42, max_iter=50)\n",
        "\n",
        "\n",
        "model_mlp2 = Sequential()\n",
        "model_mlp2.add(Dense(500, input_dim=X_train.shape[1]))\n",
        "model_mlp2.add(BatchNormalization())\n",
        "model_mlp2.add(Activation(activation='sigmoid'))\n",
        "model_mlp2.add(Dropout(0.2))\n",
        "model_mlp2.add(Dense(250))\n",
        "model_mlp2.add(BatchNormalization())\n",
        "model_mlp2.add(Activation(activation='relu'))\n",
        "model_mlp2.add(Dropout(0.2))\n",
        "model_mlp2.add(Dense(100))\n",
        "model_mlp2.add(BatchNormalization())\n",
        "model_mlp2.add(Activation(activation='sigmoid'))\n",
        "model_mlp2.add(Dropout(0.2))\n",
        "model_mlp2.add(Dense(50))\n",
        "model_mlp2.add(BatchNormalization())\n",
        "model_mlp2.add(Activation(activation='sigmoid'))\n",
        "model_mlp2.add(Dropout(0.2))\n",
        "model_mlp2.add(Dense(1,activation=tf.keras.activations.sigmoid))\n",
        "model_mlp2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define CNN model\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "model_cnn.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(128, activation='relu'))\n",
        "model_cnn.add(Dense(len(set(y_train)), activation='softmax'))\n",
        "model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define RNN model\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "model_rnn.add(LSTM(64, return_sequences=True))\n",
        "model_rnn.add(LSTM(32))\n",
        "model_rnn.add(Dense(128, activation='relu'))\n",
        "model_rnn.add(Dense(len(set(y_train)), activation='softmax'))\n",
        "model_rnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "model_lstm.add(LSTM(128))\n",
        "model_lstm.add(Dense(64, activation='relu'))\n",
        "model_lstm.add(Dense(len(set(y_train)), activation='softmax'))\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Evaluate and compare models\n",
        "# Initialize classifiers\n",
        "NN = {\n",
        "    \"Modern MLPt\": model_mlp2,\n",
        "    \"CNN\": model_cnn,\n",
        "    \"Recurrent NN\": model_rnn,\n",
        "    \"LSTM\": model_lstm,\n",
        "}\n",
        "\n",
        "# Loop through each classifier and evaluate performance\n",
        "for name, clf in NN.items():\n",
        "  clf.fit(X_train_val, y_train_val, epochs=numepochs)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  if (y_pred.ndim > 1): y_pred = np.argmax(y_pred , axis=1)\n",
        "\n",
        "\n",
        "  print_results(y_test , y_pred, name + ', '+ current_options)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def contains_suggestion(paragraph):\n",
        "    suggestion_keywords = [\"should\", \"could\", \"might\", \"ought to\", \"would\", \"recommend\", \"suggest\", \"consider\"]\n",
        "    polite_phrases = [\"would you mind\", \"could you please\", \"I suggest\", \"please\", \"if you want to\"]\n",
        "    for keyword in suggestion_keywords:\n",
        "        if keyword in paragraph.lower():\n",
        "            return True\n",
        "    for phrase in polite_phrases:\n",
        "        if phrase in paragraph.lower():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def classify_paragraphs(paragraphs):\n",
        "    suggestions = []\n",
        "    other_paragraphs = []\n",
        "    for paragraph in paragraphs:\n",
        "        if contains_suggestion(paragraph):\n",
        "            suggestions.append(paragraph)\n",
        "        else:\n",
        "            other_paragraphs.append(paragraph)\n",
        "    return suggestions, other_paragraphs\n",
        "\n",
        "# Example list of paragraphs\n",
        "paragraphs = [\n",
        "    \"You should try the new restaurant.\",\n",
        "    \"I suggest you take a break and relax.\",\n",
        "    \"The meeting lasted two hours.\",\n",
        "    \"I believe that exercise is important for maintaining good health.\"\n",
        "]\n",
        "\n",
        "suggestions, other_paragraphs = classify_paragraphs(test_df['sentence'])\n",
        "\n",
        "print(\"Paragraphs containing suggestions:\")\n",
        "for suggestion in suggestions:\n",
        "    print(\"-\", suggestion)\n",
        "\n",
        "print(\"\\nOther paragraphs:\")\n",
        "for paragraph in other_paragraphs:\n",
        "    print(\"-\", paragraph)\n"
      ],
      "metadata": {
        "id": "kq0dRjOaPM3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9o02SgiTxpA"
      },
      "source": [
        "**Word2vec Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edGIdtSDWH_H",
        "outputId": "c1dbb18d-8c8f-4cf6-9214-6b9aa64371cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGd22J1bWTKf"
      },
      "outputs": [],
      "source": [
        "wv = api.load('word2vec-google-news-300')\n",
        "#wv.save('/content/drive/MyDrive/Content Creation/YASH/vectors.kv')\n",
        "wv['apple']#vector represnation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "oRhDG6ZIRWMG",
        "outputId": "dcdd0ffd-40b5-48f3-dc20-620d8316e965"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[675  71]\n",
            " [ 29  58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93       746\n",
            "           1       0.45      0.67      0.54        87\n",
            "\n",
            "    accuracy                           0.88       833\n",
            "   macro avg       0.70      0.79      0.73       833\n",
            "weighted avg       0.91      0.88      0.89       833\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classifier = MLPClassifier(hidden_layer_sizes=(150,100,50),\n",
        "                           max_iter=40,activation = 'relu',\n",
        "                           solver='adam',random_state=1).fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "classifier.fit(X_train,y_train); plt.plot(classifier.loss_curve_,label=\"train\")\n",
        "classifier.fit(X_valid,y_valid); plt.plot(classifier.loss_curve_,label=\"validation\")\n",
        "classifier.fit(X_test,y_test); plt.plot(classifier.loss_curve_,label=\"test\")\n",
        "\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Misclassification Rate/Loss\");\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('mlp-tfidf-training')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.stdout =sys.__stdout__\n",
        "print(sys.__stdout__, 'hello')"
      ],
      "metadata": {
        "id": "srLyr5o-dVVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Balanced Classification**\n",
        "\n",
        "This experiments trains an ensemble of random forests on the balanced subsets"
      ],
      "metadata": {
        "id": "vS--U_kAR4xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Separate instances for class 1\n",
        "class_1_instances = X_train_val[y_train_val == 1,:]\n",
        "class_0_instances = X_train_val[y_train_val == 0,:]\n",
        "num_classifiers = 15\n",
        "classifiers = []\n",
        "number_of_samples = class_1_instances.shape[0]\n",
        "# Build an ensemble of classifiers (Random Forests in this example)\n",
        "\n",
        "for ks in range(1,num_classifiers+1):\n",
        "  # Randomly sample 2000 instances from class 0\n",
        "  indices = np.random.choice(class_0_instances.shape[0], number_of_samples, replace=True)\n",
        "\n",
        "  sampled_class_0_instances = class_0_instances[indices,:]\n",
        "\n",
        "  # Combine instances for class 1 and sampled instances from class 0\n",
        "  balanced_X = np.concatenate([class_1_instances, sampled_class_0_instances])\n",
        "  balanced_y = np.concatenate([np.ones(class_1_instances.shape[0]), np.zeros(sampled_class_0_instances.shape[0])])\n",
        "\n",
        "  classifier = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
        "  #classifier = sklearn.linear_model.LogisticRegression(random_state=42)\n",
        "  classifier.fit(balanced_X, balanced_y)\n",
        "  classifiers.append(classifier)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  print_results(y_test , y_pred,  current_options)\n",
        "\n",
        "# Make predictions on the test set using each classifier\n",
        "predictions = [classifier.predict(X_test) for classifier in classifiers]\n",
        "\n",
        "# Take a majority vote to get the final ensemble prediction\n",
        "ensemble_predictions = np.mean(predictions, axis=0) > 0.5\n",
        "\n",
        "# Evaluate the ensemble performance\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(f'Ensemble Accuracy: {ensemble_accuracy}')\n"
      ],
      "metadata": {
        "id": "R-gOUwRaR5VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Longest Common Subsequence**"
      ],
      "metadata": {
        "id": "3fF6EUfhxT42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def longest_common_subsequence(str1, str2):\n",
        "    words1 = str1.split()\n",
        "    words2 = str2.split()\n",
        "\n",
        "    m = len(words1)\n",
        "    n = len(words2)\n",
        "\n",
        "    # Initializing the dp table with zeros\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    # Building the dp table\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if words1[i - 1] == words2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
        "            else:\n",
        "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
        "\n",
        "    # Backtracking to find the longest common subsequence\n",
        "    lcs_length = dp[m][n]\n",
        "    lcs = []\n",
        "    i = m\n",
        "    j = n\n",
        "    while i > 0 and j > 0:\n",
        "        if words1[i - 1] == words2[j - 1]:\n",
        "            lcs.append ( words1[i - 1])\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "            lcs_length -= 1\n",
        "        elif dp[i - 1][j] > dp[i][j - 1]:\n",
        "            i -= 1\n",
        "        else:\n",
        "            j -= 1\n",
        "\n",
        "    lcs.reverse()\n",
        "    return lcs , (2*len(lcs))/ (1+m+n) # 1 is denom is there to prevent div by 0\n",
        "# Example usage:\n",
        "str1        = \"roses are red. violets are blue\"\n",
        "str2        = \"the garden is full of roses and violets that are blue \"\n",
        "lcs12 , r12 = longest_common_subsequence(str1, str2)\n",
        "print(f\"Longest Common Subsequence:{r12}: {lcs12} \")\n"
      ],
      "metadata": {
        "id": "cKfUYz7WxTPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6f4025-985d-4b62-8758-e3d21cfcb6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest Common Subsequence:0.4444444444444444: ['roses', 'violets', 'are', 'blue'] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords_list(tokens):\n",
        "  filtered_tokens = [w for w in tokens if not w.lower() in stop_words]\n",
        "  return filtered_tokens\n",
        "\n",
        "def remove_stopwords_str(str):\n",
        "  str = re.sub(r'[^A-Za-z0-9]+', ' ', str)\n",
        "  str = re.sub(r'\\W+', ' ', str)\n",
        "  str = re.sub(r'\\s+', ' ', str)\n",
        "\n",
        "  tokens = str.split()\n",
        "  filtered_tokens = [w for w in tokens if not w.lower() in stop_words]\n",
        "  return ' '.join(filtered_tokens)\n",
        "\n",
        "#--------------------\n",
        "#\n",
        "\n",
        "do_lcs = True # switch this flag if you want to run lcs\n",
        "\n",
        "if do_lcs:\n",
        "  train = train_df['sentence'].tolist(); train  = [remove_stopwords_str(s) for s in train ]\n",
        "  test  = test_df['sentence'].tolist();  test   = [remove_stopwords_str(s) for s in test ]\n",
        "  valid = valid_df['sentence'].tolist(); valid  = [remove_stopwords_str(s) for s in valid ]\n",
        "\n",
        "  orig_stdout = sys.stdout;  f = open('out05.txt', 'w'); sys.stdout = f\n",
        "\n",
        "  num_train = len(train); num_valid = len(valid); num_test  = len(test)\n",
        "  for m in range(num_train):\n",
        "    for n in range(num_valid):\n",
        "      temp, r = longest_common_subsequence (train[m], valid[n])\n",
        "      if r >= 0.1:\n",
        "        print(f\"({m}, {n})\\t({y_train[m]}, {y_valid[n]}, ),\\t{r:0.02f},\\t{len(temp)},\\t{temp}\")\n",
        "  #---\n",
        "  sys.stdout = orig_stdout ;   f.close()\n"
      ],
      "metadata": {
        "id": "LzLh7vJ0xZpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8129f95-7e55-498d-b46b-24b1a55a8219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\mmr\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords_str(str):\n",
        "  re.sub(r'[^A-Za-z0-9]+', ' ', str)\n",
        "  re.sub(r'\\W+', ' ', str)\n",
        "  re.sub(r'\\s+', ' ', str)\n",
        "\n",
        "s = train_df['sentence'][7]\n",
        "print(s, remove_stopwords_str(s))"
      ],
      "metadata": {
        "id": "GI9hpnwlBxsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**A teste of ResNet**"
      ],
      "metadata": {
        "id": "gYDNUM-aoPJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Assuming X_train contains your text data and y_train contains the corresponding labels\n",
        "num_classes = 2\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_val, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_val, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Load pre-trained ResNet\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "# Remove the fully connected layer\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "# Freeze ResNet parameters\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define classifier on top of ResNet\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(X_train_val.shape[0], 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, num_classes)  # num_classes is the number of classes in your classification task\n",
        ")\n",
        "\n",
        "# Combine ResNet and classifier\n",
        "model = nn.Sequential(\n",
        "    resnet,\n",
        "    nn.Flatten(),\n",
        "    classifier\n",
        ")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # Adjust as needed\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Print average loss for each epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = (predicted == y_val_tensor).sum().item() / len(y_val_tensor)\n",
        "    print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "bzZ3VGqxoQEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Define BiLSTM model\n",
        "# Define BiLSTM model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        output, _ = self.lstm(text)\n",
        "        hidden = torch.cat((output[:, -1, :hidden_dim], output[:, 0, hidden_dim:]), dim=1)\n",
        "        return self.fc(hidden)\n",
        "\n",
        "\n",
        "# Define model parameters\n",
        "input_dim = X_train_vec.shape[1]\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 2  # Assuming binary classification\n",
        "dropout = 0.5\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = BiLSTM(input_dim, hidden_dim, output_dim, dropout)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        print(type(inputs))\n",
        "        outputs = model(inputs)\n",
        "        print('OK2')\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = (predicted == y_val_tensor).sum().item() / len(y_val_tensor)\n",
        "    print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "-lQqDBXfqYP9",
        "outputId": "fba169d7-c924-46f1-f1bd-f4d8ab779712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[212], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(hidden)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Define model parameters\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     36\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     37\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
            "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}